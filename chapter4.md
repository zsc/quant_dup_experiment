# 第四章：实验设计与方法论

本章详细阐述层复制补偿技术的实验设计，包括实验目标、评估体系、基线模型选择、实验变量设计以及可调整的量化参数空间。通过系统化的实验设计，我们旨在探索 2-bit 权重量化下保持模型质量的最优策略。

## 章节概览

- **4.1 实验目标与评估指标**：明确实验的核心目标和评估框架
- **4.2 基线模型选择**：选择 Qwen 和 DeepSeek-MoE 作为代表性模型
- **4.3 实验变量设计**：系统化设计量化位宽、激活量化和复制策略
- **4.4 可调整的量化参数**：详细说明所有可优化的量化超参数空间

---

## 4.1 实验目标与评估指标

### 4.1.1 核心实验目标

#### 主要目标：极低比特量化下的精度保持
- **目标配置**：在 Apple M1 Pro (32GB) 上运行 32B 参数模型
- **量化目标**：2-bit 权重量化 + 8/16-bit 激活量化
- **质量要求**：PPL 损失控制在可接受范围内（相比 FP16 基线）
- **创新点**：通过层复制技术补偿量化误差，无需重训练

#### 次要目标：探索 1-bit 量化的可行性
- **实验意义**：验证方法在极限条件下的有效性
- **预期结果**：即使质量下降明显，只要优于现有 1-bit 方法即可
- **技术挑战**：1-bit 量化的信息损失极其严重，需要更激进的补偿策略

### 4.1.2 评估指标体系

#### 质量指标

**1. 困惑度（Perplexity, PPL）**
- **主要指标**：使用标准测试集（WikiText-2, C4, PTB）
- **计算方法**：
  ```
  PPL = exp(-1/N * Σ log P(xi|x<i))
  ```
- **评估标准**：
  - 优秀：PPL 增加 < 0.5
  - 良好：PPL 增加 < 1.0
  - 可接受：PPL 增加 < 2.0
  - 对于 1-bit：PPL 增加 < 10.0

**2. 下游任务性能**（辅助指标）
- **任务选择**：MMLU, HellaSwag, ARC-Challenge
- **评估方式**：Zero-shot 和 Few-shot 性能
- **重要性**：验证模型的实际应用能力

**3. 生成质量评估**
- **人工评估**：随机抽样生成文本的流畅性和连贯性
- **自动指标**：BLEU, ROUGE（与 FP16 生成结果对比）

#### 性能指标

**1. 推理延迟**
- **首 Token 延迟（TTFT）**：模型响应时间
- **Token 生成速度**：tokens/秒吞吐量
- **批处理性能**：不同 batch size 下的扩展性

**2. 内存使用**
- **模型大小**：量化后的模型文件大小
- **运行时内存**：推理时的峰值内存占用
- **KV Cache 优化**：长文本场景下的内存效率

**3. 计算带宽利用率**
- **理论带宽利用率**：实际带宽 / 理论峰值带宽
- **计算强度**：FLOPs / 内存访问字节数
- **层复制开销**：额外计算 vs 带宽节省的权衡

### 4.1.3 实验约束与假设

#### 硬件约束
- **目标平台**：Apple M1 Pro (10-core CPU, 16-core GPU, 32GB unified memory)
- **内存带宽**：200 GB/s
- **计算能力**：2.6 TFLOPS (FP32), 10.4 TFLOPS (FP16)

#### 软件框架
- **量化实验**：PyTorch 2.0+ 
- **量化库**：BitsAndBytes, AutoGPTQ (可根据需要修改)
- **部署框架**：llama.cpp (支持自定义 GGUF 格式)

#### 基本假设
1. **单层内存驻留**：单个 Transformer 层可完全载入 GPU/NPU 内存
2. **带宽瓶颈**：权重加载是主要性能瓶颈（compute-bound → memory-bound）
3. **线性扩展**：层复制的计算开销与复制次数线性相关

---

## 4.2 基线模型选择

### 4.2.1 模型选择原则

#### 代表性要求
- **架构多样性**：覆盖密集模型和 MoE 模型两大主流架构
- **规模适中**：32B 参数级别，在 M1 Pro 上可行但具有挑战性
- **开源可用**：完整的模型权重和架构细节公开
- **社区活跃**：有丰富的基线结果和优化经验可参考

#### 技术考量
- **量化友好性**：模型架构不包含对量化特别敏感的组件
- **推理优化**：已有成熟的推理框架支持（如 llama.cpp）
- **评估基准**：有标准的评估集和已发表的基线结果

### 4.2.2 Qwen 系列（密集模型代表）

#### 模型概况
- **选择型号**：Qwen2-32B（Base model）
- **架构特点**：
  - 标准 Transformer 架构，RMSNorm 归一化
  - GQA (Grouped Query Attention) 优化
  - SwiGLU 激活函数
  - RoPE 位置编码

#### 量化相关特性
- **激活分布**：相对均匀，异常值问题较轻
- **权重分布**：接近正态分布，适合对称量化
- **层间差异**：前层和后层的量化敏感度差异明显

#### 基线性能（FP16）
- **WikiText-2 PPL**：约 4.5
- **推理速度**：~15 tokens/s (M1 Pro, batch=1)
- **内存占用**：~64GB（FP16 权重）

### 4.2.3 DeepSeek-MoE（稀疏模型代表）

#### 模型概况
- **选择型号**：DeepSeek-MoE-32B
- **架构特点**：
  - Mixture of Experts (MoE) 架构
  - 16 个 experts，Top-2 路由
  - 共享 attention 层，专家化 FFN 层
  - 激活参数约 8B（稀疏激活）

#### MoE 特殊考虑
- **Expert 利用率**：不同 expert 的激活频率差异很大
- **路由稳定性**：量化可能影响 expert 选择
- **稀疏性保持**：确保量化后的稀疏激活模式不被破坏

#### 量化挑战
- **Expert 间差异**：不同 expert 的量化敏感度差异显著
- **Router 精度**：gate/router 需要保持较高精度
- **负载不均衡**：热门 expert 的量化误差影响更大

#### 基线性能（FP16）
- **WikiText-2 PPL**：约 4.2
- **推理速度**：~20 tokens/s (M1 Pro, batch=1, 稀疏激活)
- **内存占用**：~64GB（全部 experts）

### 4.2.4 模型预处理流程

#### 权重转换
1. **HuggingFace → PyTorch**：统一使用 PyTorch checkpoint 格式
2. **权重分析**：计算每层权重的统计特性（均值、方差、峰度）
3. **敏感度评估**：使用小批量数据评估各层的量化敏感度

#### 校准数据准备
- **数据集**：C4 validation set 的子集
- **样本数量**：128 个样本
- **序列长度**：2048 tokens
- **预处理**：标准 tokenization，无特殊处理

#### 基线评估
1. **FP16 基线**：在所有测试集上建立 FP16 性能基准
2. **现有量化方法**：评估 GPTQ、AWQ 等方法的 4-bit 性能
3. **旋转方法基线**：评估 QuaRot、DFRot 的效果

---

## 4.3 实验变量设计

### 4.3.1 量化位宽配置

#### 权重量化位宽
**主要实验配置（2-bit）**
- **量化格式**：INT2（-2, -1, 0, 1）或 (0, 1, 2, 3) with zero-point
- **量化粒度**：
  - Per-channel：每个输出通道独立量化
  - Per-group：128/256 个元素为一组
  - Sub-channel：更细粒度的分组（实验性）

**极限实验配置（1-bit）**
- **二值量化**：{-1, +1} 或 {0, 1}
- **三值量化**：{-1, 0, +1}（提供额外的零值表示）
- **量化策略**：需要更激进的补偿机制

**混合精度探索**
- **层间混合**：关键层保持较高位宽（如 4-bit）
- **通道混合**：重要通道使用更高精度
- **基于敏感度的自适应位宽分配**

#### 激活量化位宽
**标准配置（8-bit）**
- **INT8 量化**：标准的 8-bit 整数表示
- **动态范围**：per-token 动态量化
- **裁剪策略**：基于分位数的激活裁剪

**高精度配置（16-bit）**
- **FP16/BF16**：保持激活的浮点表示
- **INT16**：更大的整数表示范围
- **应用场景**：对激活特别敏感的层

### 4.3.2 层复制策略设计

#### 基础复制策略
**1. 全局统一复制**
- **复制次数**：所有层统一复制 1 次（2x 层数）
- **排列方式**：Layer_k → Layer_k_copy → Layer_k+1 → Layer_k+1_copy
- **参数共享**：完全共享量化后的权重

**2. 选择性层复制**
- **敏感层识别**：基于量化误差分析选择需要复制的层
- **复制比例**：通常复制 30-50% 的层
- **选择标准**：
  - PPL 贡献度最大的层
  - 量化误差最大的层
  - 包含巨大激活值的层

**3. 渐进式复制**
- **前层密集复制**：模型前部的层复制更多次
- **后层稀疏复制**：模型后部的层复制较少或不复制
- **理论依据**：前层特征提取对精度影响更大

#### 高级复制策略
**1. 串行 vs 并行复制**
```
串行：x → Layer_k → Layer_k_copy1 → Layer_k_copy2 → output
并行：x → [Layer_k, Layer_k_copy1, Layer_k_copy2] → aggregate → output
```

**2. 差异化参数配置**
- **不同 scaling factors**：每个复制层使用不同的量化参数
- **不同 clipping thresholds**：激活裁剪阈值的差异化
- **互补量化网格**：量化网格偏移以覆盖更多数值范围

**3. 动态复制决策**
- **基于输入的自适应复制**：根据输入特征动态决定复制次数
- **早停机制**：当复制收益递减时停止
- **计算预算约束**：在给定计算预算下最优化复制策略

### 4.3.3 旋转集成策略

#### 旋转与复制的结合
**1. 预旋转 + 复制**
- 先应用 Hadamard/正交变换消除异常值
- 再进行层复制以补偿量化误差
- 优势：两种技术的互补效应

**2. 多旋转集成**
- 不同复制层使用不同的旋转矩阵
- 创造更大的表示空间多样性
- 计算开销：需要多次旋转变换

**3. 部分旋转策略**
- 仅对包含巨大激活值的层应用旋转
- 其他层直接复制
- 平衡计算开销和精度提升

### 4.3.4 实验组织结构

#### 实验阶段划分
**Phase 1：基础实验**
- 建立 2-bit 量化基线
- 验证简单层复制的有效性
- 确定最佳复制次数

**Phase 2：参数优化**
- 探索差异化量化参数
- 优化 scaling factor 和 zero point
- 调整量化组大小

**Phase 3：高级策略**
- 实现选择性层复制
- 集成旋转技术
- 探索并行复制架构

**Phase 4：极限探索**
- 1-bit 量化实验
- 最大化复制策略
- 性能极限测试

#### 对照实验设计
| 实验组 | 权重位宽 | 激活位宽 | 复制策略 | 旋转 | 预期结果 |
|-------|---------|---------|---------|------|---------|
| Baseline | 16-bit | 16-bit | 无 | 无 | PPL 基准 |
| GPTQ-4bit | 4-bit | 16-bit | 无 | 无 | 标准量化基线 |
| Simple-2bit | 2-bit | 8-bit | 全局1次 | 无 | 验证基础方法 |
| Selective-2bit | 2-bit | 8-bit | 选择性 | 无 | 优化复制策略 |
| Rotated-2bit | 2-bit | 8-bit | 选择性 | 是 | 最优配置 |
| Extreme-1bit | 1-bit | 8-bit | 多次复制 | 是 | 极限探索 |

---

## 4.4 可调整的量化参数

### 4.4.1 权重量化参数

#### Scaling Factor（缩放因子）
**定义与作用**
- **公式**：`W_quant = round(W_float / scale) * scale`
- **作用**：控制量化的数值范围映射
- **优化目标**：最小化量化重建误差

**优化策略**
1. **MSE 最优**：最小化均方误差
   ```
   scale_opt = argmin ||W - W_quant||²
   ```
2. **感知优化**：考虑激活值分布的加权优化
3. **层级优化**：每层独立优化 vs 全局统一

**搜索空间**
- **初始化**：基于权重范围的启发式初始值
- **搜索范围**：[0.5×初始值, 2.0×初始值]
- **优化方法**：网格搜索、二分搜索或梯度下降

#### Zero Point（零点）
**对称 vs 非对称量化**
- **对称量化**：zero_point = 0，简化计算
- **非对称量化**：可调整的 zero_point，更好的表示范围
- **权衡**：计算复杂度 vs 表示精度

**优化考虑**
- **权重分布偏移**：当权重分布不对称时特别有效
- **硬件友好性**：某些硬件对对称量化有优化
- **与 scaling factor 联合优化**

#### Group Size（量化组大小）
**粒度选择**
- **Per-tensor**：整个张量共享参数（最粗粒度）
- **Per-channel**：每个输出通道独立（标准选择）
- **Per-group**：固定大小的元素组（细粒度）
  - 常见选择：32, 64, 128, 256
  - 权衡：精度 vs 存储开销

**自适应分组**
- **基于方差的分组**：高方差区域使用更小的组
- **基于重要性的分组**：关键通道使用更细的粒度
- **动态分组**：根据权重分布自适应确定组边界

### 4.4.2 激活量化参数

#### 动态范围确定
**Per-token 量化**
- **动态计算**：每个 token 独立计算量化参数
- **优势**：适应激活值的动态变化
- **开销**：需要实时计算统计量

**Calibration-based 量化**
- **离线校准**：使用校准数据集确定固定参数
- **百分位选择**：如 99.9% 分位数作为裁剪阈值
- **移动平均**：平滑多个 batch 的统计信息

#### Clipping Threshold（裁剪阈值）
**裁剪策略**
1. **固定百分位**：如裁剪到 99.9 分位数
2. **基于 KL 散度**：最小化裁剪前后的分布差异
3. **学习型阈值**：通过反向传播学习最优阈值

**巨大激活值处理**
- **识别巨大激活值**：超过 3σ 的激活
- **特殊处理**：保持 FP16 或使用更高位宽
- **混合精度**：普通值 INT8 + 异常值 FP16

### 4.4.3 高级量化参数

#### Grid Offset（量化网格偏移）
**概念说明**
- **标准网格**：{0, 1, 2, 3} for 2-bit
- **偏移网格**：{0.5, 1.5, 2.5, 3.5}
- **作用**：通过偏移覆盖不同的数值范围

**复制层的差异化偏移**
- **互补偏移**：不同复制层使用不同偏移
- **覆盖优化**：最大化数值空间覆盖
- **示例配置**：
  - Layer_k: offset = 0
  - Layer_k_copy: offset = 0.5

#### Rounding Mode（舍入模式）
**舍入选择**
1. **最近邻舍入**（Round-to-Nearest）
   - 标准选择，确定性
   - 可能导致系统偏差

2. **随机舍入**（Stochastic Rounding）
   - 概率性舍入，无偏估计
   - 更好的期望值保持
   - 需要随机数生成器

3. **偏置感知舍入**
   - 根据局部误差累积调整舍入方向
   - 减少系统性偏差

#### Noise Injection（噪声注入）
**量化噪声建模**
- **加性噪声**：`W_quant = W + ε`
- **噪声水平**：通常为量化步长的 0.1-0.5 倍
- **作用**：提高模型对量化误差的鲁棒性

**差异化噪声策略**
- **不同复制层使用不同噪声水平**
- **训练时注入，推理时固定**
- **与随机舍入的协同效应**

### 4.4.4 参数搜索与优化

#### 搜索策略
**1. 网格搜索**
- **优点**：全面覆盖参数空间
- **缺点**：计算开销大
- **适用**：参数空间较小时

**2. 贝叶斯优化**
- **优点**：高效探索高维空间
- **缺点**：需要先验知识
- **适用**：参数较多时

**3. 进化算法**
- **优点**：可处理离散和连续参数
- **缺点**：收敛较慢
- **适用**：复杂约束条件

#### 优化目标与约束
**多目标优化**
```
minimize: α·PPL_loss + β·size + γ·latency
subject to: memory < threshold
```

**参数约束**
- **硬件约束**：某些参数组合可能不被硬件支持
- **精度约束**：PPL 增加不超过阈值
- **复杂度约束**：推理时的计算开销限制

#### 参数初始化指南
| 参数类型 | 推荐初始值 | 搜索范围 | 优化优先级 |
|---------|-----------|----------|-----------|
| Weight Scale | 基于范围 | [0.5x, 2x] | 高 |
| Weight Zero Point | 0（对称） | [-0.5, 0.5] | 中 |
| Act Scale | 基于校准 | [0.8x, 1.2x] | 高 |
| Group Size | 128 | {64, 128, 256} | 中 |
| Clip Percentile | 99.9 | [99.0, 99.99] | 高 |
| Grid Offset | 0 | [0, 0.5] | 低 |
| Noise Level | 0 | [0, 0.3] | 低 |
