# LLM 量化与层复制加速实验

## 实验概述

本实验书探索通过层复制技术补偿极低比特量化带来的精度损失，目标是在 M1 Pro 上实现 32B 模型的 2-bit 权重量化，同时保持极小的 PPL 损失。核心思想是通过共享权重的集成方法，用计算换取内存带宽，提高计算访存比。
选用 2-bit 是因为机器资源只支持 2-bit。为了深入研究方法，还会做 1-bit 实验（quality 可能掉的较多，但只要比以前方法有进步即可）

**实验框架选择**：
- **量化实验**：PyTorch + BitsAndBytes/AutoGPTQ（Python 环境，易于实验和修改）
- **部署推理**：转换到 llama.cpp GGUF 格式（Apple Silicon 优化）

## 目录

### 第一章：现代 LLM 量化技术概述
- 1.1 量化基础概念
  - 权重量化 vs 激活量化
  - 量化精度对模型性能的影响
- 1.2 主流量化方法
  - GPTQ (Generative Pre-trained Transformer Quantization)
  - AWQ (Activation-aware Weight Quantization)
  - SmoothQuant
  - GGUF/GGML
- 1.3 量化挑战与计算访存比
  - 内存带宽瓶颈
  - 极低比特量化的精度损失

### 第二章：旋转技术与异常值处理
- 2.1 旋转技术基础
  - Hadamard 变换 vs 正交变换
  - 计算不变性原理
  - 权重融合与在线计算优化
- 2.2 异常值与巨大激活值问题
  - 传统异常值（outliers）的影响
  - 巨大激活值（massive activations）的发现
  - 为什么 Hadamard 优于正交变换
- 2.3 旋转矩阵优化
  - Procrustes 问题与 SVD 求解
  - 长尾优化与加权损失函数
  - 最小化在线计算开销

### 第三章：层复制补偿理论
- 3.1 核心思想：通过冗余降低量化误差
  - 共享权重的集成方法
  - 2-bit 量化的挑战与机遇
- 3.2 计算访存比优化原理
  - 单层内存驻留的优势
  - 带宽利用率分析
  - 用计算换带宽的权衡
- 3.3 层复制策略设计
  - 基础策略：相邻层共享权重
  - 进阶策略：差异化量化参数
  - 最小化训练需求的设计原则

### 第四章：实验设计与方法论
- 4.1 实验目标与评估指标
  - 目标：32B 模型在 M1 Pro 上 2-bit 权重量化
  - 评估：困惑度 (PPL) 损失
  - 性能记录：延迟、带宽利用率
- 4.2 基线模型选择
  - Qwen 系列（密集模型）
  - DeepSeek-MoE（混合专家模型）
- 4.3 实验变量设计
  - 量化位宽：1-bit, 2-bit, 混合精度权重
  - 激活量化：8-bit, 16-bit
  - 复制策略：单次复制、多次复制、选择性复制
- 4.4 可调整的量化参数
  - 权重量化：scaling factor, zero point
  - 激活量化：scaling factor, zero point
  - 量化组大小（group size）
  - 量化网格偏移（grid offset）
  - 每通道 vs 每组量化策略
  - 激活裁剪阈值
  - 量化噪声注入水平
  - 舍入模式：最近邻 vs 随机舍入

### 第五章：高级优化技术
- 5.1 旋转与复制的协同优化
  - 巨大激活值的特殊处理
  - 通过多种旋转产生 ensemble 策略
- 5.2 自适应层选择算法
  - 基于敏感度的层选择
  - 考虑巨大激活值分布的决策
- 5.3 共享权重集成优化
  - 差异化量化参数搜索
  - 参数组合优化策略
- 5.4 最小化训练方案
  - 仅调整量化参数的轻量级训练
  - 冻结权重的 QAT 变体


### 第六章：密集模型实验（Qwen）
- 6.1 Qwen 模型架构分析
- 6.2 旋转与层复制结合
  - 通过多种旋转产生 ensemble 策略
  - 旋转参数对复制效果的影响
- 6.3 基础层复制实验
  - 全层复制 vs 选择性复制
  - 性能与精度权衡
- 6.4 差异化量化参数实验
  - Scaling factor 优化
  - 量化组大小调整
- 6.5 结果分析与讨论

### 第七章：MoE 模型实验（DeepSeek）
- 7.1 MoE 架构的特殊考虑
  - Expert 选择机制
  - 稀疏激活的影响
- 7.2 Expert 旋转与复制策略
  - 巨大激活值在 Expert 中的分布
  - 重要 Expert 识别（基于量化敏感度）
  - 通过多种旋转产生 ensemble 策略
  - 选择性 Expert 复制
  - Router/Gate 保持全精度
- 7.3 MoE 特定优化结果


### 第八章：性能评估与分析
- 8.1 推理速度基准测试
  - Token/秒吞吐量
  - 首 Token 延迟
- 8.2 内存使用分析
  - 模型大小压缩比
  - 运行时内存占用
- 8.3 精度保持评估
  - 各种任务的 PPL 对比
  - 下游任务性能

### 第九章：实用部署指南
- 9.1 量化流程设计
  - Python 环境下的量化实验
  - 旋转矩阵集成
  - 层复制逻辑实现
- 9.2 模型格式转换
  - PyTorch → GGUF 转换流程
  - 旋转与复制元数据保存
  - 差异化参数存储
- 9.3 推理优化
  - llama.cpp 自定义算子
  - Apple Silicon Metal 优化
  - 内存带宽利用策略

### 第十章：结论与展望
- 10.1 实验发现总结
- 10.2 旋转与层复制的协同效应
- 10.3 方法适用场景分析
- 10.4 未来研究方向
  - 更激进的量化目标
  - 自动化旋转与复制决策
  - 硬件协同设计

### 附录 A：旋转量化技术详解（QuaRot 与 DFRot）

#### A.1 QuaRot：通过旋转实现无异常值 4-bit 推理
(confer quarot.md for details)
- **核心创新**
  - 计算不变性原理：RMSNorm(X) = RMSNorm(XQ^T)Q
  - 使用随机 Hadamard 变换消除异常值
  - 权重融合技术，仅需 1.5 个 Hadamard 变换/层
- **技术细节**
  - 第一阶段：权重修改，融合 LayerNorm/RMSNorm 缩放
  - 第二阶段：在线量化操作，INT4 权重和激活
  - KV cache 量化：使用非对称量化，组大小 128
- **实验结果**
  - LLAMA2-70B：0.47 WikiText-2 PPL 损失
  - 3.33× 预填充加速，3.89× 内存节省
  - RTN 在 8-bit 可实现无损量化
- **实现要点**
  - GPTQ 权重量化，128 样本 × 2048 长度校准
  - 对称 per-token 激活量化，裁剪比 0.9
  - CUTLASS INT4 矩阵乘法，FlashInfer KV 缓存

#### A.2 DFRot：巨大激活值的发现与优化
(confer dfrot.md for details)
- **关键发现**
  - RH 优于 RO 的根本原因：巨大激活值（massive activations）
  - RO 增加巨大激活值的量化误差
  - RH 仅轻微减少巨大激活值误差
  - 保留巨大激活值为 FP16 可消除 RH/RO 性能差距
- **优化方法**
  - 长尾优化：加权损失函数 L = L_normal + γ²L_massive
  - Procrustes 问题求解：SVD 优化旋转矩阵
  - 交替优化：量化参数 ↔ 旋转矩阵
- **实验设置**
  - 仅需 1 个样本 × 2048 tokens 优化旋转矩阵
  - γ ∈ [50, 200] 效果最佳
  - 优化 100 轮，A100 上 8-90 分钟
- **性能提升**
  - LLaMA3-70B：0.95-0.98 PPL 改进
  - 无需重训练，仅后处理优化
  - 对巨大激活值敏感模型效果更显著

#### A.3 技术对比与启示
- **量化策略差异**
  - QuaRot：全局 Hadamard + 局部优化
  - DFRot：针对巨大激活值的定向优化
- **计算开销**
  - QuaRot：在线 Hadamard 变换开销
  - DFRot：离线优化，推理无额外开销
- **适用场景**
  - QuaRot：通用 4-bit 量化基线
  - DFRot：巨大激活值问题严重时的增强
- **对层复制的启示**
  - 先旋转消除异常值，再复制补偿量化误差
  - 巨大激活值可能需要特殊复制策略
  - 旋转参数可与复制参数联合优化

### 附录 B：实验代码与复现指南

### 附录 C：详细实验数据表格

### 附录 D：相关论文引用
